{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data colleciton and selection\n",
    "In this notebook, the raw data of interest from the last manikin tests are gathered and filtered. Only the selected steady state 15' intervals are kept and stored into CSV files. There will be 7 (= number configurations) CSV files per HOBO sensor (including relative humidity) and cube sensor, one for the flowmeter, siemens log, manikin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOBO sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "hoboAcronyms = ['AH1', 'AH2', 'AH3',\n",
    "                'BH1', 'BH2', 'BH3',\n",
    "                'CH1', 'CH2', 'CH3',\n",
    "                'DH1', 'DH2', 'DH3']\n",
    "\n",
    "def create_hobo_DFs(date, test):\n",
    "    ''' test is a string looking like 8.1 or 9.2\n",
    "        date is the date in the folder nomenclature, eg 20231106\n",
    "        returns a pandas dataframes list for all hobo sensors of one test\n",
    "    '''\n",
    "\n",
    "    file_path = 'Y:/PROJECTS/ManikinStudies/2_2023_Diego Houtart/040. Data/010. Raw/{} - Manikin Test {}/HOBO/{}_{}.csv'\n",
    "    hoboCSVFiles = [file_path.format(date, test, date, hoboAcronym) for hoboAcronym in hoboAcronyms]\n",
    "\n",
    "\n",
    "    # Specify the date and time format\n",
    "    date_time_format = '%m.%d.%y %I:%M:%S %p' \n",
    "\n",
    "    dtypes = {\n",
    "        0: 'int',\n",
    "        1: 'float64',\n",
    "        2: 'float64',\n",
    "        3: 'float64',\n",
    "        4: 'float64',\n",
    "        5: 'float64',\n",
    "        6: 'str',\n",
    "        7: 'str',\n",
    "        8: 'str'\n",
    "    }\n",
    "\n",
    "    # dfs will be a list of pandas dataframes, each element corresponding to a hobo sensor\n",
    "    # Skip rows that are not multiples of 10 and not the header\n",
    "    # and avoid taking the first row which is useless in the file\n",
    "    dfs = [pd.read_csv(file,\n",
    "                    dtype=dtypes,\n",
    "                    skiprows=1, \n",
    "                    parse_dates=['Date Heure, GMT+01:00'],\n",
    "                    date_format=date_time_format\n",
    "                    )\n",
    "        for file in hoboCSVFiles]\n",
    "\n",
    "\n",
    "    for df in dfs:\n",
    "        df.drop(df.tail(1).index,inplace=True) #drop last rows that can be not well written\n",
    "        cols_to_drop = df.filter(like='Hôte connecté').columns.tolist() + \\\n",
    "                        df.filter(like='Arrêté').columns.tolist() + \\\n",
    "                        df.filter(like='Fin de fichier').columns.tolist() # drop recording-related columns\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "        df.drop(columns=df.columns[-1:], axis=1,  inplace=True) #drop last useless column anemometer temperature\n",
    "        df.drop(columns=df.columns[0], inplace=True) #drop first column with index, not useful\n",
    "        df.columns = ['Date and Time', 'T_a [°C]','T_g [°C]', 'v_a [mA]'] #rename columns\n",
    "        df['Date and Time'] = pd.to_datetime(df['Date and Time'], format=date_time_format)\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "def save_hobo_period_csv(hobo_dfs, configName, start_time, end_time):\n",
    "    ''' Save a list of csv files corresponding to one configuration \n",
    "        during its specified time interval between start_time and end_time.\n",
    "        Each csv of the list correspond to a hobo sensor.\n",
    "    '''\n",
    "    \n",
    "    filtered_dfs = [] \n",
    "    for i in range(len(hobo_dfs)):\n",
    "        mask = (hobo_dfs[i]['Date and Time'] >= start_time) & (hobo_dfs[i]['Date and Time'] <= end_time)\n",
    "        filtered_dfs.append(hobo_dfs[i][mask])\n",
    "        \n",
    "\n",
    "    for filtered_df,hoboAcronym in zip(filtered_dfs, hoboAcronyms):\n",
    "        filtered_df.to_csv(f'HOBO/{configName}_{hoboAcronym}.csv', index=False, sep='\\t')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "hobo_sensors_8_1 = create_hobo_DFs('20231106', '8.1')\n",
    "hobo_sensors_9_1 = create_hobo_DFs('20231108', '9.1')\n",
    "\n",
    "# Save CSV\n",
    "save_hobo_period_csv(hobo_sensors_9_1, 'floorConfig0', '2023-11-06 22:45:00', '2023-11-06 23:00:00')\n",
    "save_hobo_period_csv(hobo_sensors_9_1, 'floorConfig1', '2023-11-07 00:45:00', '2023-11-07 01:00:00')\n",
    "save_hobo_period_csv(hobo_sensors_9_1, 'floorConfig2a', '2023-11-07 16:45:00', '2023-11-07 17:00:00')\n",
    "save_hobo_period_csv(hobo_sensors_8_1, 'floorConfig2b', '2023-11-05 05:25:00', '2023-11-05 05:40:00')\n",
    "save_hobo_period_csv(hobo_sensors_8_1, 'floorConfig3', '2023-11-05 12:25:00', '2023-11-05 12:40:00')\n",
    "save_hobo_period_csv(hobo_sensors_9_1, 'floorConfig4', '2023-11-08 00:45:00', '2023-11-08 01:00:00')\n",
    "save_hobo_period_csv(hobo_sensors_9_1, 'floorConfig6', '2023-11-08 05:45:00', '2023-11-08 06:00:00')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOBO relative humidity sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def create_hobo_RH_DF(date, test):\n",
    "    ''' test is a string looking like 8.1 or 9.2\n",
    "        date is the date in the folder nomenclature, eg 20231106\n",
    "        returns a pandas dataframes list for all hobo sensors of one test\n",
    "    '''\n",
    "\n",
    "    file_path = 'Y:/PROJECTS/ManikinStudies/2_2023_Diego Houtart/040. Data/010. Raw/{} - Manikin Test {}/HOBO_RH/{}_RH1.csv'\n",
    "    hobo_RH_CSV_File = file_path.format(date, test, date)\n",
    "\n",
    "\n",
    "    # Specify the date and time format\n",
    "    date_time_format = '%m.%d.%y %I:%M:%S %p' \n",
    "\n",
    "    dtypes = {\n",
    "        0: 'int',\n",
    "        1: 'float64',\n",
    "        2: 'float64',\n",
    "        3: 'float64',\n",
    "        6: 'str',\n",
    "        7: 'str',\n",
    "        8: 'str'\n",
    "    }\n",
    "\n",
    "    # dfs will be a list of pandas dataframes, each element corresponding to a hobo sensor\n",
    "    # Skip rows that are not multiples of 10 and not the header\n",
    "    # and avoid taking the first row which is useless in the file\n",
    "    df = pd.read_csv(hobo_RH_CSV_File,\n",
    "                    dtype=dtypes,\n",
    "                    skiprows=1, \n",
    "                    parse_dates=['Date Heure, GMT+01:00'],\n",
    "                    date_format=date_time_format\n",
    "                    )\n",
    "\n",
    "\n",
    "    df.drop(df.tail(1).index,inplace=True) #drop last rows that can be not well written\n",
    "    cols_to_drop = df.filter(like='Hôte connecté').columns.tolist() + \\\n",
    "                    df.filter(like='Arrêté').columns.tolist() + \\\n",
    "                    df.filter(like='Fin de fichier').columns.tolist() # drop recording-related columns\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    df.drop(columns=df.columns[0], inplace=True) #drop first column with index, not useful\n",
    "    df.columns = ['Date and Time', 'T_a [°C]','RH [°%]'] #rename columns\n",
    "    df['Date and Time'] = pd.to_datetime(df['Date and Time'], format=date_time_format)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_hobo_rh_period_csv(hobo_rh_df, configName, start_time, end_time):\n",
    "    ''' Save a list of csv files corresponding to one configuration \n",
    "        during its specified time interval between start_time and end_time.\n",
    "        Each csv of the list correspond to a hobo sensor.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    mask = (hobo_rh_df['Date and Time'] >= start_time) & (hobo_rh_df['Date and Time'] <= end_time)\n",
    "    filtered_df = hobo_rh_df[mask]\n",
    "        \n",
    "    filtered_df.to_csv(f'HOBO_RH/{configName}_RH.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "hobo_rh_8_1 = create_hobo_RH_DF('20231106', '8.1')\n",
    "\n",
    "# Save CSV\n",
    "save_hobo_rh_period_csv(hobo_rh_8_1, 'floorConfig2b', '2023-11-05 05:25:00', '2023-11-05 05:40:00')\n",
    "save_hobo_rh_period_csv(hobo_rh_8_1, 'floorConfig3', '2023-11-05 12:25:00', '2023-11-05 12:40:00')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOBO Airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "hobo_AF_Acronyms = ['Extract', 'Supply']\n",
    "\n",
    "def create_hobo_AF_DFs(date, test):\n",
    "    ''' test is a string looking like 8.1 or 9.2\n",
    "        date is the date in the folder nomenclature, eg 20231106\n",
    "        returns a pandas dataframes list for all hobo sensors of one test\n",
    "    '''\n",
    "\n",
    "    file_path = 'Y:/PROJECTS/ManikinStudies/2_2023_Diego Houtart/040. Data/010. Raw/{} - Manikin Test {}/HOBO_AIRFLOW/{}_{}.csv'\n",
    "    hobo_AF_CSVFiles = [file_path.format(date, test, date, hobo_AF_Acronym) for hobo_AF_Acronym in hobo_AF_Acronyms]\n",
    "\n",
    "\n",
    "    # Specify the date and time format\n",
    "    date_time_format = '%m.%d.%y %I:%M:%S %p' \n",
    "\n",
    "    dtypes = {\n",
    "        0: 'int',\n",
    "        1: 'float64',\n",
    "        2: 'float64',\n",
    "        6: 'str',\n",
    "        7: 'str',\n",
    "        8: 'str'\n",
    "    }\n",
    "\n",
    "    # dfs will be a list of pandas dataframes, each element corresponding to a hobo sensor\n",
    "    # Skip rows that are not multiples of 10 and not the header\n",
    "    # and avoid taking the first row which is useless in the file\n",
    "    dfs = [pd.read_csv(file,\n",
    "                    dtype=dtypes,\n",
    "                    skiprows=1, \n",
    "                    parse_dates=['Date Heure, GMT+01:00'],\n",
    "                    date_format=date_time_format\n",
    "                    )\n",
    "        for file in hobo_AF_CSVFiles]\n",
    "\n",
    "\n",
    "    for df in dfs:\n",
    "        df.drop(df.tail(1).index,inplace=True) #drop last rows that can be not well written\n",
    "        cols_to_drop = df.filter(like='Hôte connecté').columns.tolist() + \\\n",
    "                        df.filter(like='Arrêté').columns.tolist() + \\\n",
    "                        df.filter(like='Fin de fichier').columns.tolist() # drop recording-related columns\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "        df.drop(columns=df.columns[0], inplace=True) #drop first column with index, not useful\n",
    "        df.columns = ['Date and Time', 'T_a [°C]'] #rename columns\n",
    "        df['Date and Time'] = pd.to_datetime(df['Date and Time'], format=date_time_format)\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "def save_hobo_AF_period_csv(hobo_AF_dfs, configName, start_time, end_time):\n",
    "    ''' Save a list of csv files corresponding to one configuration \n",
    "        during its specified time interval between start_time and end_time.\n",
    "        Each csv of the list correspond to a hobo sensor.\n",
    "    '''\n",
    "    \n",
    "    filtered_dfs = [] \n",
    "    for i in range(len(hobo_AF_dfs)):\n",
    "        mask = (hobo_AF_dfs[i]['Date and Time'] >= start_time) & (hobo_AF_dfs[i]['Date and Time'] <= end_time)\n",
    "        filtered_dfs.append(hobo_AF_dfs[i][mask])\n",
    "        \n",
    "\n",
    "    for filtered_df,hobo_AF_Acronym in zip(filtered_dfs, hobo_AF_Acronyms):\n",
    "        filtered_df.to_csv(f'HOBO_AF/{configName}_{hobo_AF_Acronym}.csv', index=False, sep='\\t')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "hobo_AF_sensors_8_1 = create_hobo_AF_DFs('20231106', '8.1')\n",
    "hobo_AF_sensors_9_1 = create_hobo_AF_DFs('20231108', '9.1')\n",
    "\n",
    "# Save CSV\n",
    "save_hobo_AF_period_csv(hobo_AF_sensors_9_1, 'floorConfig0', '2023-11-06 22:45:00', '2023-11-06 23:00:00')\n",
    "save_hobo_AF_period_csv(hobo_AF_sensors_9_1, 'floorConfig1', '2023-11-07 00:45:00', '2023-11-07 01:00:00')\n",
    "save_hobo_AF_period_csv(hobo_AF_sensors_9_1, 'floorConfig2a', '2023-11-07 16:45:00', '2023-11-07 17:00:00')\n",
    "save_hobo_AF_period_csv(hobo_AF_sensors_8_1, 'floorConfig2b', '2023-11-05 05:25:00', '2023-11-05 05:40:00')\n",
    "save_hobo_AF_period_csv(hobo_AF_sensors_8_1, 'floorConfig3', '2023-11-05 12:25:00', '2023-11-05 12:40:00')\n",
    "save_hobo_AF_period_csv(hobo_AF_sensors_9_1, 'floorConfig4', '2023-11-08 00:45:00', '2023-11-08 01:00:00')\n",
    "save_hobo_AF_period_csv(hobo_AF_sensors_9_1, 'floorConfig6', '2023-11-08 05:45:00', '2023-11-08 06:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUBES sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "cubeAcronyms = ['BC1', 'BC2', 'CC1', 'DC1', 'DC2']\n",
    "\n",
    "def create_cubes_DFs(date, test):\n",
    "    ''' test is a string looking like 8.1 or 9.2\n",
    "        date is the date in the folder nomenclature, eg 20231106\n",
    "        returns a pandas dataframes list for all hobo sensors of one test\n",
    "    '''\n",
    "\n",
    "    file_path = 'Y:/PROJECTS/ManikinStudies/2_2023_Diego Houtart/040. Data/010. Raw/{} - Manikin Test {}/CUBES/{}_{}.csv'\n",
    "    cubeCSVFiles = [file_path.format(date, test, date, cubeAcronym) for cubeAcronym in cubeAcronyms]\n",
    "\n",
    "\n",
    "    # Specify the date and time format\n",
    "    date_time_format = \"%d-%m-%Y  %H:%M:%S\"\n",
    "\n",
    "    pat = r\".+?{}?$\".format(\"([^,]+),\"*19)\n",
    "   \n",
    "    dfs = [pd.read_csv(file,\n",
    "                    header=0,\n",
    "                    skiprows=range(1, 3),\n",
    "                    on_bad_lines = 'skip',\n",
    "                    sep=pat,\n",
    "                    engine='python'\n",
    "                    ).dropna(how=\"all\", axis=1)\n",
    "        for file in cubeCSVFiles]\n",
    "\n",
    "    dfs_copies = []\n",
    "    for df, i in zip(dfs, range(len(dfs))):\n",
    "        columns_to_drop = df.filter(like='Unnamed').columns\n",
    "        df.drop(columns=columns_to_drop, inplace=True)\n",
    "        df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "        df['DD-MM-YYYY'] = df['DD-MM-YYYY'].str.strip(' ')\n",
    "        df['HH:MM:SS'] = df['HH:MM:SS'].str.strip(' ')\n",
    "        df = df[~df.apply(lambda row: row.astype(str).str.contains('DD-MM-YYYY')).any(axis=1)]\n",
    "        df.insert(0, 'Date and Time', pd.to_datetime(df['DD-MM-YYYY'] + ' ' + df['HH:MM:SS'], format=date_time_format, errors='coerce'))\n",
    "        df.dropna(axis=0,inplace=True)\n",
    "        df.drop(['DD-MM-YYYY', 'HH:MM:SS'], axis=1, inplace=True)\n",
    "        df.drop(df.tail(1).index,inplace=True) #drop last rows that can be not well written\n",
    "        dfs_copies.append(df.copy())\n",
    "    return dfs_copies\n",
    "\n",
    "\n",
    "\n",
    "def save_cube_period_csv(cube_dfs, configName, start_time, end_time):\n",
    "    ''' Save a list of csv files corresponding to one configuration \n",
    "        during its specified time interval between start_time and end_time.\n",
    "        Each csv of the list correspond to a cube sensor.\n",
    "    '''\n",
    "    \n",
    "    filtered_dfs = [] \n",
    "    for i in range(len(cube_dfs)):\n",
    "        mask = (cube_dfs[i]['Date and Time'] >= start_time) & (cube_dfs[i]['Date and Time'] <= end_time)\n",
    "        filtered_dfs.append(cube_dfs[i][mask])\n",
    "        \n",
    "\n",
    "    for filtered_df,cubeAcronym in zip(filtered_dfs, cubeAcronyms):\n",
    "        filtered_df.to_csv(f'CUBES/{configName}_{cubeAcronym}.csv', index=False, sep='\\t')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(axis=0,inplace=True)\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['DD-MM-YYYY', 'HH:MM:SS'], axis=1, inplace=True)\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(df.tail(1).index,inplace=True) #drop last rows that can be not well written\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(axis=0,inplace=True)\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['DD-MM-YYYY', 'HH:MM:SS'], axis=1, inplace=True)\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(df.tail(1).index,inplace=True) #drop last rows that can be not well written\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(axis=0,inplace=True)\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['DD-MM-YYYY', 'HH:MM:SS'], axis=1, inplace=True)\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(df.tail(1).index,inplace=True) #drop last rows that can be not well written\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(axis=0,inplace=True)\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['DD-MM-YYYY', 'HH:MM:SS'], axis=1, inplace=True)\n",
      "C:\\Users\\houtart\\AppData\\Local\\Temp\\ipykernel_20976\\2770424432.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(df.tail(1).index,inplace=True) #drop last rows that can be not well written\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "cube_sensors_8_1 = create_cubes_DFs('20231106', '8.1')\n",
    "cube_sensors_9_1 = create_cubes_DFs('20231108', '9.1')\n",
    "\n",
    "# CSV\n",
    "save_cube_period_csv(cube_sensors_9_1, 'floorConfig0', '2023-11-06 22:45:00', '2023-11-06 23:00:00')\n",
    "save_cube_period_csv(cube_sensors_9_1, 'floorConfig1', '2023-11-07 00:45:00', '2023-11-07 01:00:00')\n",
    "save_cube_period_csv(cube_sensors_9_1, 'floorConfig2a', '2023-11-07 16:45:00', '2023-11-07 17:00:00')\n",
    "save_cube_period_csv(cube_sensors_8_1, 'floorConfig2b', '2023-11-05 05:25:00', '2023-11-05 05:40:00')\n",
    "save_cube_period_csv(cube_sensors_8_1, 'floorConfig3', '2023-11-05 12:25:00', '2023-11-05 12:40:00')\n",
    "save_cube_period_csv(cube_sensors_9_1, 'floorConfig4', '2023-11-08 00:45:00', '2023-11-08 01:00:00')\n",
    "save_cube_period_csv(cube_sensors_9_1, 'floorConfig6', '2023-11-08 05:45:00', '2023-11-08 06:00:00')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLOWMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "flowmeter_acronyms = ['A', 'B']\n",
    "def create_flowmeter_DFs(date, test):\n",
    "    ''' Create and returns two dataframe for the specified date and test. \n",
    "        One df for A and one for B measurements combined\n",
    "        Flowmeter were in summer time, 1 hour is retrieved to timestamps\n",
    "    '''\n",
    "    a_header = ['Date and Time', 'Chanel', 'Flow (L/s)', 'Q_POS', 'Q_NEG', 'T1', 'T2', 'SSPEED', 'AMP', 'SCNR']\n",
    "    b_header = ['Date and Time', 'Chanel', 'Flow (L/s)', 'Q_POS', 'Q_NEG', 'T3', 'T4', 'SSPEED', 'AMP', 'SCNR']\n",
    "\n",
    "    date_time_format = \"%Y/%m/%d %H:%M:%S,%f\"\n",
    "\n",
    "    file_path = fr'Y:\\PROJECTS\\ManikinStudies\\2_2023_Diego Houtart\\040. Data\\010. Raw\\{date} - Manikin Test {test}\\FLOWMETER'\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(file_path, \"*.txt\")) # we make a list of all log files of the flowmeter\n",
    "    dfs_a = []\n",
    "    dfs_b = []\n",
    "    for f in all_files: # we create one dataframe for A and one for B, combining all files\n",
    "        with open(f, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            # Data is encoded in a unusual way in the txt\n",
    "            data = [list(map(lambda x: x.strip(' :'), re.split(r'[;\\t]', line.strip()))) for line in lines]\n",
    "            data_a = [data[i] for i in range(len(data)) if i % 2 == 0]\n",
    "            data_b = [data[i] for i in range(len(data)) if i % 2 != 0]\n",
    "            df_a = pd.DataFrame(data_a, columns=a_header)\n",
    "            df_b = pd.DataFrame(data_b, columns=b_header)\n",
    "            dfs_a.append(df_a); dfs_b.append(df_b)\n",
    "    combined_df_a = pd.concat(dfs_a, ignore_index=True)\n",
    "    combined_df_b = pd.concat(dfs_b, ignore_index=True)\n",
    "\n",
    "\n",
    "    cols_to_drop = ['Q_POS', 'Q_NEG', 'SSPEED', 'AMP', 'SCNR']\n",
    "    for df in [combined_df_a, combined_df_b]:\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "        df['Date and Time'] = pd.to_datetime(df['Date and Time'], format=date_time_format, errors='coerce')\n",
    "        df['Date and Time'] = df['Date and Time'] - pd.Timedelta(hours=1)\n",
    "        df['Date and Time'] = df['Date and Time'].astype('datetime64[s]')\n",
    "\n",
    "    return [combined_df_a, combined_df_b]\n",
    "\n",
    "def save_flowmeter_period_csv(flowmeter_dfs, configName, start_time, end_time):\n",
    "    ''' Save a list of csv files corresponding to one configuration \n",
    "        during its specified time interval between start_time and end_time.\n",
    "        Each csv of the list correspond to a cube sensor.\n",
    "    '''\n",
    "    \n",
    "    filtered_dfs = [] \n",
    "    for i in range(len(flowmeter_dfs)):\n",
    "        mask = (flowmeter_dfs[i]['Date and Time'] >= start_time) & (flowmeter_dfs[i]['Date and Time'] <= end_time)\n",
    "        filtered_dfs.append(flowmeter_dfs[i][mask])\n",
    "        \n",
    "\n",
    "    for filtered_df,flowmeter_acronym in zip(filtered_dfs, flowmeter_acronyms):\n",
    "        filtered_df.to_csv(f'FLOWMETER/{configName}_{flowmeter_acronym}.csv', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "flowmeters_8_1 = create_flowmeter_DFs('20231106', '8.1')\n",
    "flowmeters_9_1 = create_flowmeter_DFs('20231108', '9.1')\n",
    "\n",
    "# CSV\n",
    "save_flowmeter_period_csv(flowmeters_9_1, 'floorConfig0', '2023-11-06 22:45:00', '2023-11-06 23:00:00')\n",
    "save_flowmeter_period_csv(flowmeters_9_1, 'floorConfig1', '2023-11-07 00:45:00', '2023-11-07 01:00:00')\n",
    "save_flowmeter_period_csv(flowmeters_9_1, 'floorConfig2a', '2023-11-07 16:45:00', '2023-11-07 17:00:00')\n",
    "save_flowmeter_period_csv(flowmeters_8_1, 'floorConfig2b', '2023-11-05 05:25:00', '2023-11-05 05:40:00')\n",
    "save_flowmeter_period_csv(flowmeters_8_1, 'floorConfig3', '2023-11-05 12:25:00', '2023-11-05 12:40:00')\n",
    "save_flowmeter_period_csv(flowmeters_9_1, 'floorConfig4', '2023-11-08 00:45:00', '2023-11-08 01:00:00')\n",
    "save_flowmeter_period_csv(flowmeters_9_1, 'floorConfig6', '2023-11-08 05:45:00', '2023-11-08 06:00:00')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MANIKIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def create_manikin_DF(date, test):\n",
    "    ''' test is a string looking like 8.1 or 9.2\n",
    "        date is the date in the folder nomenclature, eg 20231106\n",
    "        returns a pandas dataframes list for all hobo sensors of one test\n",
    "    '''\n",
    "\n",
    "    file_path = f'Y:/PROJECTS/ManikinStudies/2_2023_Diego Houtart/040. Data/010. Raw/{date} - Manikin Test {test}/MANIKIN/{date}_Manikin.csv'\n",
    "\n",
    "\n",
    "    # Specify the date and time format\n",
    "    date_time_format = '%m/%d/%Y %I:%M:%S %p' \n",
    "\n",
    "\n",
    "    manikin_df = pd.read_csv(file_path,\\\n",
    "        encoding='ansi',\\\n",
    "        sep='\\t',\\\n",
    "        header=[0,1,2],\n",
    "        skiprows=3)\n",
    "\n",
    "    header_tuples = [\n",
    "        ('Date and Time', ' ', ' '),\n",
    "        ('Runtime', ' ', 'sec')]\n",
    "    next_header_tuples = [(a, b, c) \\\n",
    "        for a in ['All','Group A','Group B'] \\\n",
    "        for b, c in zip(\n",
    "            ['T','P','Teq','PMV','PPD','SET*','ET*'],\n",
    "            ['degC','W/m²','degC', ' ','%','degC','degC'])]\n",
    "\n",
    "    header_tuples.extend(next_header_tuples)\n",
    "    next_header_tuples = [(a, b, c) \\\n",
    "        for a in [\n",
    "            'L. Foot','R. Foot','L. Foreleg','R. Foreleg',\\\n",
    "            'L. Front Thigh','R. Front Thigh','L. Back Thigh',\\\n",
    "            'R. Back Thigh','Pelvis','Back Side','Head','Schll',\\\n",
    "            'L. Hand','R. Hand','L. Forearm','R. Forearm',\\\n",
    "            'L. Upper Arm','R. Upper Arm','Chest',\\\n",
    "            'Low Back','Upper Back','Stomach'] \\\n",
    "        for b, c in zip(\n",
    "            ['T','P','Teq','MTV'],\n",
    "            ['degC','W/m²','degC', ' '])]\n",
    "\n",
    "    header_tuples.extend(next_header_tuples)\n",
    "    next_tuples = [\n",
    "        ('Stability', ' ', ' '),\n",
    "        ('','','')]\n",
    "    header_tuples.extend(next_tuples)\n",
    "    manikin_df.columns = pd.MultiIndex.from_tuples(header_tuples)\n",
    "    manikin_df = manikin_df.iloc[:,:-1] # Delete last column (all N/A)\n",
    "\n",
    "    manikin_df = manikin_df.drop(['Runtime', 'Group A', 'Group B'], axis=1, level=0)\n",
    "    manikin_df['Date and Time', ' ', ' '] = pd.to_datetime(manikin_df['Date and Time', ' ', ' '], format=date_time_format, errors='raise')\n",
    "    return manikin_df\n",
    "\n",
    "\n",
    "def save_manikin_period_csv(manikin_df, configName, start_time, end_time):\n",
    "    ''' Save a csv files corresponding to one configuration \n",
    "        during its specified time interval between start_time and end_time.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    mask = (manikin_df['Date and Time', ' ', ' '] >= start_time) & (manikin_df['Date and Time', ' ', ' '] <= end_time)\n",
    "    filtered_df = manikin_df[mask]\n",
    "        \n",
    "    filtered_df.to_csv(f'MANIKIN/{configName}_manikin.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "manikin_8_1 = create_manikin_DF('20231106', '8.1')\n",
    "manikin_9_1 = create_manikin_DF('20231108', '9.1')\n",
    "\n",
    "# CSV\n",
    "save_manikin_period_csv(manikin_9_1, 'floorConfig0', '2023-11-06 22:45:00', '2023-11-06 23:00:00')\n",
    "save_manikin_period_csv(manikin_9_1, 'floorConfig1', '2023-11-07 00:45:00', '2023-11-07 01:00:00')\n",
    "save_manikin_period_csv(manikin_9_1, 'floorConfig2a', '2023-11-07 16:45:00', '2023-11-07 17:00:00')\n",
    "save_manikin_period_csv(manikin_8_1, 'floorConfig2b', '2023-11-05 05:25:00', '2023-11-05 05:40:00')\n",
    "save_manikin_period_csv(manikin_8_1, 'floorConfig3', '2023-11-05 12:25:00', '2023-11-05 12:40:00')\n",
    "save_manikin_period_csv(manikin_9_1, 'floorConfig4', '2023-11-08 00:45:00', '2023-11-08 01:00:00')\n",
    "save_manikin_period_csv(manikin_9_1, 'floorConfig6', '2023-11-08 05:45:00', '2023-11-08 06:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIEMENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def create_siemens_DF(date, test):\n",
    "    ''' test is a string looking like 8.1 or 9.2\n",
    "        date is the date in the folder nomenclature, eg 20231106\n",
    "        returns a pandas dataframes list for all hobo sensors of one test\n",
    "    '''\n",
    "\n",
    "    date_time_format = '%Y-%m-%d %H:%M:%S'\n",
    "    file_path = 'Y:/PROJECTS/ManikinStudies/2_2023_Diego Houtart/040. Data/010. Raw/{} - Manikin Test {}/SIEMENS/{}_siemens_log.csv'\n",
    "    siemens_CSV_File = file_path.format(date, test, date)\n",
    "\n",
    "    # dfs will be a list of pandas dataframes, each element corresponding to a hobo sensor\n",
    "    # Skip rows that are not multiples of 10 and not the header\n",
    "    # and avoid taking the first row which is useless in the file\n",
    "    df = pd.read_csv(siemens_CSV_File,\n",
    "                    header=[0]\n",
    "                    )\n",
    "\n",
    "\n",
    "    df.drop(df.tail(1).index,inplace=True) #drop last rows that can be not well written\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format=date_time_format)\n",
    "    df.rename(columns={'Timestamp': 'Date and Time'}, inplace=True)    \n",
    "    return df\n",
    "\n",
    "def save_siemens_period_csv(siemens_df, configName, start_time, end_time):\n",
    "    ''' Save a list of csv files corresponding to one configuration \n",
    "        during its specified time interval between start_time and end_time.\n",
    "        Each csv of the list correspond to a hobo sensor.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    mask = (siemens_df['Date and Time'] >= start_time) & (siemens_df['Date and Time'] <= end_time)\n",
    "    filtered_df = siemens_df[mask]\n",
    "        \n",
    "    filtered_df.to_csv(f'SIEMENS/{configName}_siemens.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "siemens_8_1 = create_siemens_DF('20231106', '8.1')\n",
    "siemens_9_1 = create_siemens_DF('20231108', '9.1')\n",
    "\n",
    "\n",
    "\n",
    "save_siemens_period_csv(siemens_9_1, 'floorConfig0', '2023-11-06 22:45:00', '2023-11-06 23:00:00')\n",
    "save_siemens_period_csv(siemens_8_1, 'floorConfig2b', '2023-11-05 05:25:00', '2023-11-05 05:40:00')\n",
    "save_siemens_period_csv(siemens_8_1, 'floorConfig3', '2023-11-05 12:25:00', '2023-11-05 12:40:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THERMOCOUPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def create_TC_DF(date, test):\n",
    "    ''' test is a string looking like 8.1 or 9.2\n",
    "        date is the date in the folder nomenclature, eg 20231106\n",
    "        returns a pandas dataframe for the thermocouples of one test\n",
    "    '''\n",
    "\n",
    "    date_time_format = '%d.%m.%Y %H.%M.%S'\n",
    "    file_path = 'Y:/PROJECTS/ManikinStudies/2_2023_Diego Houtart/040. Data/010. Raw/{} - Manikin Test {}/THERMOCOUPLES/{}_TC.txt'\n",
    "    siemens_CSV_File = file_path.format(date, test, date)\n",
    "\n",
    "    # dfs will be a list of pandas dataframes, each element corresponding to a hobo sensor\n",
    "    # Skip rows that are not multiples of 10 and not the header\n",
    "    # and avoid taking the first row which is useless in the file\n",
    "    TC_cols_file_path = r'Y:\\PROJECTS\\ManikinStudies\\2_2023_Diego Houtart\\040. Data\\000. External\\Thermocouples nomenclature\\thermocouples_order.txt'\n",
    "    with open(TC_cols_file_path) as TC_cols_file:\n",
    "            TC_cols = TC_cols_file.read().split(', ')\n",
    "    TC_cols = ['DD.MM.YYYY', 'HH.MM.SS'] + TC_cols\n",
    "    df = pd.read_csv(siemens_CSV_File,\n",
    "                    header=None,\n",
    "                    names=TC_cols,\n",
    "                    sep='\\t',\n",
    "                    decimal=','\n",
    "                    )\n",
    "\n",
    "\n",
    "    df.drop(df.tail(1).index,inplace=True) #drop last rows that can be not well written\n",
    "    df.insert(0, 'Date and Time', pd.to_datetime(df['DD.MM.YYYY'] + ' ' + df['HH.MM.SS'], format=date_time_format, errors='coerce')) \n",
    "    df.drop(['DD.MM.YYYY', 'HH.MM.SS'], axis=1, inplace=True) \n",
    "    df = df.loc[:, ~df.columns.str.contains('Channel')]\n",
    "    return df\n",
    "\n",
    "def save_TC_period_csv(tc_df, configName, start_time, end_time):\n",
    "    ''' Save a list of csv files corresponding to one configuration \n",
    "        during its specified time interval between start_time and end_time.\n",
    "        Each csv of the list correspond to a hobo sensor.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    mask = (tc_df['Date and Time'] >= start_time) & (tc_df['Date and Time'] <= end_time)\n",
    "    filtered_df = tc_df[mask]\n",
    "        \n",
    "    filtered_df.to_csv(f'THERMOCOUPLES/{configName}_TC.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "TC_8_1 = create_TC_DF('20231106', '8.1')\n",
    "TC_9_1 = create_TC_DF('20231108', '9.1')\n",
    "\n",
    "# CSV\n",
    "save_TC_period_csv(TC_9_1, 'floorConfig0', '2023-11-06 22:45:00', '2023-11-06 23:00:00')\n",
    "save_TC_period_csv(TC_9_1, 'floorConfig1', '2023-11-07 00:45:00', '2023-11-07 01:00:00')\n",
    "save_TC_period_csv(TC_9_1, 'floorConfig2a', '2023-11-07 16:45:00', '2023-11-07 17:00:00')\n",
    "save_TC_period_csv(TC_8_1, 'floorConfig2b', '2023-11-05 05:25:00', '2023-11-05 05:40:00')\n",
    "save_TC_period_csv(TC_8_1, 'floorConfig3', '2023-11-05 12:25:00', '2023-11-05 12:40:00')\n",
    "save_TC_period_csv(TC_9_1, 'floorConfig4', '2023-11-08 00:45:00', '2023-11-08 01:00:00')\n",
    "save_TC_period_csv(TC_9_1, 'floorConfig6', '2023-11-08 05:45:00', '2023-11-08 06:00:00')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
